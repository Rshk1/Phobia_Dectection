{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phobia Detection Using Virtual Reality/ Augmented Reality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#citations:\n",
    "1. Data set:\n",
    "    https://www.researchgate.net/publication/329403546_Mental_Emotional_Sentiment_Classification_with_an_EEG-based_Brain-machine_Interface\n",
    "\n",
    "2. Research Material: \n",
    "    https://www.researchgate.net/publication/335173767_A_Deep_Evolutionary_Approach_to_Bioinspired_Classifier_Optimisation_for_Brain-Machine_Interaction\n",
    "\n",
    "3. J. J. Bird, L. J. Manso, E. P. Ribiero, A. Ekart, and D. R. Faria, “A study on mental state classification using eeg-based brain-machine     interface,”in 9th International Conference on Intelligent Systems, IEEE, 2018.\n",
    "\n",
    "4. J. J. Bird, A. Ekart, C. D. Buckingham, and D. R. Faria, “Mental emotional sentiment classification with an eeg-based brain-machine interface,” in The International Conference on Digital Image and Signal Processing (DISP’19), Springer, 2019.\n",
    "\n",
    "This research was part supported by the EIT Health GRaCE-AGE grant number 18429 awarded to C.D. Buckingham.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Team Members: \n",
    "1. Avishkar Borkar\n",
    "2. Harshal Makote\n",
    "3. Sourabh Waghmode\n",
    "4. Rushikesh Sapkal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why this project in particular ?\n",
    "## What is the scope ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The motivation behind this project is that in today’s age, thousands of people suffer from mental hardships and conditions. I wish to raise awareness for the mental battles people have to go through and how these issues are often ignored. The project uses machine learning algorithms, statistics and complex python libraries such as scikit-learn, TensorFlow, etc. to predict if an individual has a particular phobia or not. The intention behind the project is that people have hidden fears and is an excellent idea to gradually expose them to their fears in a virtually controlled environment so that they can be worked upon and then further medical assistance can be provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approaching The Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Exploration\n",
    "2. Data Preparation\n",
    "3. Model Evaluation\n",
    "4. Confirming Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About Dataset\n",
    "\n",
    "<p>The data was collected from two people (1 male, 1 female) for 3 minutes per state - positive, neutral, negative. We used a Muse EEG headband which recorded the TP9, AF7, AF8 and TP10 EEG placements via dry electrodes. Six minutes of resting neutral data is also recorded, the stimuli used to evoke the emotions are below<p>\n",
    "\n",
    "Video inputs:\n",
    "\n",
    "1. Marley and Me - **NEGATIVE** (Twentieth Century Fox) ---> Death Scene \n",
    "\n",
    "2. Up - **NEGATIVE** (Walt Disney Pictures) ---> Opening Death Scene\n",
    "\n",
    "3. La La Land - **POSITIVE** (Summit Entertainment) ---> Opening musical number\n",
    "\n",
    "4. Slow Life - **POSITIVE** (BioQuest Studios) ---> Nature timelapse\n",
    "\n",
    "5. Funny Dogs - **POSITIVE** (MashupZone) ---> Funny dog clips\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.62</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>26.3</td>\n",
       "      <td>1.070</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-15.70</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.15</td>\n",
       "      <td>...</td>\n",
       "      <td>23.5</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>23.5</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>280.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>280.00</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.80</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>22.8</td>\n",
       "      <td>6.550</td>\n",
       "      <td>1.680</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.83</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>2.57</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.90</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>23.7</td>\n",
       "      <td>79.900</td>\n",
       "      <td>3.360</td>\n",
       "      <td>90.20</td>\n",
       "      <td>89.90</td>\n",
       "      <td>2.03</td>\n",
       "      <td>...</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-267.0</td>\n",
       "      <td>281.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>281.00</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.90</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>8.82</td>\n",
       "      <td>2.30</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.53</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.30</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>24.5</td>\n",
       "      <td>34.800</td>\n",
       "      <td>-5.790</td>\n",
       "      <td>3.06</td>\n",
       "      <td>41.40</td>\n",
       "      <td>5.52</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>38.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.90</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  mean_d_1_a  \\\n",
       "0        4.62      30.3    -356.0      15.6      26.3       1.070       0.411   \n",
       "1       28.80      33.1      32.0      25.8      22.8       6.550       1.680   \n",
       "2        8.90      29.4    -416.0      16.7      23.7      79.900       3.360   \n",
       "3       14.90      31.6    -143.0      19.8      24.3      -0.584      -0.284   \n",
       "4       28.30      31.3      45.2      27.3      24.5      34.800      -5.790   \n",
       "\n",
       "   mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  fft_742_b  fft_743_b  \\\n",
       "0      -15.70        2.06        3.15  ...       23.5       20.3       20.3   \n",
       "1        2.88        3.83       -4.82  ...      -23.3      -21.8      -21.8   \n",
       "2       90.20       89.90        2.03  ...      462.0     -233.0     -233.0   \n",
       "3        8.82        2.30       -1.97  ...      299.0     -243.0     -243.0   \n",
       "4        3.06       41.40        5.52  ...       12.0       38.1       38.1   \n",
       "\n",
       "   fft_744_b  fft_745_b  fft_746_b  fft_747_b  fft_748_b  fft_749_b     label  \n",
       "0       23.5     -215.0     280.00    -162.00    -162.00     280.00  NEGATIVE  \n",
       "1      -23.3      182.0       2.57     -31.60     -31.60       2.57   NEUTRAL  \n",
       "2      462.0     -267.0     281.00    -148.00    -148.00     281.00  POSITIVE  \n",
       "3      299.0      132.0     -12.40       9.53       9.53     -12.40  POSITIVE  \n",
       "4       12.0      119.0     -17.60      23.90      23.90     -17.60   NEUTRAL  \n",
       "\n",
       "[5 rows x 2549 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('emotions.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_740_b</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.256914</td>\n",
       "      <td>27.012462</td>\n",
       "      <td>-104.975629</td>\n",
       "      <td>13.605898</td>\n",
       "      <td>24.150483</td>\n",
       "      <td>0.025378</td>\n",
       "      <td>0.052282</td>\n",
       "      <td>0.301655</td>\n",
       "      <td>0.036793</td>\n",
       "      <td>0.083567</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.938971</td>\n",
       "      <td>104.946111</td>\n",
       "      <td>-51.973647</td>\n",
       "      <td>-51.973647</td>\n",
       "      <td>104.946111</td>\n",
       "      <td>-6.934144</td>\n",
       "      <td>95.104886</td>\n",
       "      <td>-49.061255</td>\n",
       "      <td>-49.061255</td>\n",
       "      <td>95.104886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.284621</td>\n",
       "      <td>9.265141</td>\n",
       "      <td>206.271960</td>\n",
       "      <td>16.874676</td>\n",
       "      <td>14.187340</td>\n",
       "      <td>17.981796</td>\n",
       "      <td>8.509174</td>\n",
       "      <td>68.098894</td>\n",
       "      <td>17.010031</td>\n",
       "      <td>18.935378</td>\n",
       "      <td>...</td>\n",
       "      <td>298.034311</td>\n",
       "      <td>212.532721</td>\n",
       "      <td>112.160233</td>\n",
       "      <td>112.160233</td>\n",
       "      <td>212.532721</td>\n",
       "      <td>281.040552</td>\n",
       "      <td>203.194976</td>\n",
       "      <td>106.486317</td>\n",
       "      <td>106.486317</td>\n",
       "      <td>203.194976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-61.300000</td>\n",
       "      <td>-114.000000</td>\n",
       "      <td>-970.000000</td>\n",
       "      <td>-137.000000</td>\n",
       "      <td>-217.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-255.000000</td>\n",
       "      <td>-1360.000000</td>\n",
       "      <td>-203.000000</td>\n",
       "      <td>-553.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1180.000000</td>\n",
       "      <td>-921.000000</td>\n",
       "      <td>-504.000000</td>\n",
       "      <td>-504.000000</td>\n",
       "      <td>-921.000000</td>\n",
       "      <td>-1160.000000</td>\n",
       "      <td>-1010.000000</td>\n",
       "      <td>-521.000000</td>\n",
       "      <td>-521.000000</td>\n",
       "      <td>-1010.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.577500</td>\n",
       "      <td>26.075000</td>\n",
       "      <td>-195.000000</td>\n",
       "      <td>4.857500</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>-3.105000</td>\n",
       "      <td>-1.340000</td>\n",
       "      <td>-4.002500</td>\n",
       "      <td>-2.905000</td>\n",
       "      <td>-2.622500</td>\n",
       "      <td>...</td>\n",
       "      <td>-106.500000</td>\n",
       "      <td>-8.365000</td>\n",
       "      <td>-92.900000</td>\n",
       "      <td>-92.900000</td>\n",
       "      <td>-8.365000</td>\n",
       "      <td>-102.500000</td>\n",
       "      <td>-8.837500</td>\n",
       "      <td>-87.150000</td>\n",
       "      <td>-87.150000</td>\n",
       "      <td>-8.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.100000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.950000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>25.200000</td>\n",
       "      <td>-0.044600</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>-0.099750</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>...</td>\n",
       "      <td>83.850000</td>\n",
       "      <td>12.150000</td>\n",
       "      <td>-21.800000</td>\n",
       "      <td>-21.800000</td>\n",
       "      <td>12.150000</td>\n",
       "      <td>89.700000</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>-24.100000</td>\n",
       "      <td>-24.100000</td>\n",
       "      <td>13.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.700000</td>\n",
       "      <td>31.400000</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>26.800000</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>6.735000</td>\n",
       "      <td>2.535000</td>\n",
       "      <td>2.870000</td>\n",
       "      <td>...</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>12.025000</td>\n",
       "      <td>12.025000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>149.250000</td>\n",
       "      <td>10.925000</td>\n",
       "      <td>10.925000</td>\n",
       "      <td>149.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>304.000000</td>\n",
       "      <td>42.300000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>402.000000</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>444.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1070.000000</td>\n",
       "      <td>843.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>843.000000</td>\n",
       "      <td>1180.000000</td>\n",
       "      <td>888.000000</td>\n",
       "      <td>1670.000000</td>\n",
       "      <td>1670.000000</td>\n",
       "      <td>888.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 2548 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        # mean_0_a     mean_1_a     mean_2_a     mean_3_a     mean_4_a  \\\n",
       "count  2132.000000  2132.000000  2132.000000  2132.000000  2132.000000   \n",
       "mean     15.256914    27.012462  -104.975629    13.605898    24.150483   \n",
       "std      15.284621     9.265141   206.271960    16.874676    14.187340   \n",
       "min     -61.300000  -114.000000  -970.000000  -137.000000  -217.000000   \n",
       "25%       6.577500    26.075000  -195.000000     4.857500    23.600000   \n",
       "50%      14.100000    30.000000    14.950000    15.400000    25.200000   \n",
       "75%      27.700000    31.400000    29.600000    26.500000    26.800000   \n",
       "max     304.000000    42.300000   661.000000   206.000000   213.000000   \n",
       "\n",
       "        mean_d_0_a   mean_d_1_a   mean_d_2_a   mean_d_3_a   mean_d_4_a  ...  \\\n",
       "count  2132.000000  2132.000000  2132.000000  2132.000000  2132.000000  ...   \n",
       "mean      0.025378     0.052282     0.301655     0.036793     0.083567  ...   \n",
       "std      17.981796     8.509174    68.098894    17.010031    18.935378  ...   \n",
       "min    -218.000000  -255.000000 -1360.000000  -203.000000  -553.000000  ...   \n",
       "25%      -3.105000    -1.340000    -4.002500    -2.905000    -2.622500  ...   \n",
       "50%      -0.044600     0.132000     0.957500    -0.099750     0.146500  ...   \n",
       "75%       2.920000     1.540000     6.735000     2.535000     2.870000  ...   \n",
       "max     402.000000   257.000000  1150.000000   349.000000   444.000000  ...   \n",
       "\n",
       "         fft_740_b    fft_741_b    fft_742_b    fft_743_b    fft_744_b  \\\n",
       "count  2132.000000  2132.000000  2132.000000  2132.000000  2132.000000   \n",
       "mean    -22.938971   104.946111   -51.973647   -51.973647   104.946111   \n",
       "std     298.034311   212.532721   112.160233   112.160233   212.532721   \n",
       "min   -1180.000000  -921.000000  -504.000000  -504.000000  -921.000000   \n",
       "25%    -106.500000    -8.365000   -92.900000   -92.900000    -8.365000   \n",
       "50%      83.850000    12.150000   -21.800000   -21.800000    12.150000   \n",
       "75%     154.000000   177.000000    12.025000    12.025000   177.000000   \n",
       "max    1070.000000   843.000000  1490.000000  1490.000000   843.000000   \n",
       "\n",
       "         fft_745_b    fft_746_b    fft_747_b    fft_748_b    fft_749_b  \n",
       "count  2132.000000  2132.000000  2132.000000  2132.000000  2132.000000  \n",
       "mean     -6.934144    95.104886   -49.061255   -49.061255    95.104886  \n",
       "std     281.040552   203.194976   106.486317   106.486317   203.194976  \n",
       "min   -1160.000000 -1010.000000  -521.000000  -521.000000 -1010.000000  \n",
       "25%    -102.500000    -8.837500   -87.150000   -87.150000    -8.837500  \n",
       "50%      89.700000    13.400000   -24.100000   -24.100000    13.400000  \n",
       "75%     153.000000   149.250000    10.925000    10.925000   149.250000  \n",
       "max    1180.000000   888.000000  1670.000000  1670.000000   888.000000  \n",
       "\n",
       "[8 rows x 2548 columns]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2132"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2132 artists>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(data['label'], height = 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2132 rows × 2549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  \\\n",
       "0          False     False     False     False     False       False   \n",
       "1          False     False     False     False     False       False   \n",
       "2          False     False     False     False     False       False   \n",
       "3          False     False     False     False     False       False   \n",
       "4          False     False     False     False     False       False   \n",
       "...          ...       ...       ...       ...       ...         ...   \n",
       "2127       False     False     False     False     False       False   \n",
       "2128       False     False     False     False     False       False   \n",
       "2129       False     False     False     False     False       False   \n",
       "2130       False     False     False     False     False       False   \n",
       "2131       False     False     False     False     False       False   \n",
       "\n",
       "      mean_d_1_a  mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  \\\n",
       "0          False       False       False       False  ...      False   \n",
       "1          False       False       False       False  ...      False   \n",
       "2          False       False       False       False  ...      False   \n",
       "3          False       False       False       False  ...      False   \n",
       "4          False       False       False       False  ...      False   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2127       False       False       False       False  ...      False   \n",
       "2128       False       False       False       False  ...      False   \n",
       "2129       False       False       False       False  ...      False   \n",
       "2130       False       False       False       False  ...      False   \n",
       "2131       False       False       False       False  ...      False   \n",
       "\n",
       "      fft_742_b  fft_743_b  fft_744_b  fft_745_b  fft_746_b  fft_747_b  \\\n",
       "0         False      False      False      False      False      False   \n",
       "1         False      False      False      False      False      False   \n",
       "2         False      False      False      False      False      False   \n",
       "3         False      False      False      False      False      False   \n",
       "4         False      False      False      False      False      False   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2127      False      False      False      False      False      False   \n",
       "2128      False      False      False      False      False      False   \n",
       "2129      False      False      False      False      False      False   \n",
       "2130      False      False      False      False      False      False   \n",
       "2131      False      False      False      False      False      False   \n",
       "\n",
       "      fft_748_b  fft_749_b  label  \n",
       "0         False      False  False  \n",
       "1         False      False  False  \n",
       "2         False      False  False  \n",
       "3         False      False  False  \n",
       "4         False      False  False  \n",
       "...         ...        ...    ...  \n",
       "2127      False      False  False  \n",
       "2128      False      False  False  \n",
       "2129      False      False  False  \n",
       "2130      False      False  False  \n",
       "2131      False      False  False  \n",
       "\n",
       "[2132 rows x 2549 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_count = data.isnull().sum().sum()\n",
    "null_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 2549 columns.\n",
      "There are 0 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Values, % of Total Values]\n",
       "Index: []"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def missing_values_table(df):\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "    '% of Total Values', ascending=False).round(1)\n",
    "    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "            \" columns that have missing values.\")\n",
    "    return mis_val_table_ren_columns\n",
    "\n",
    "missing_values_table(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we have 0 null values, we will proceed with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop([\"label\"] , axis=1)\n",
    "\n",
    "#Scaling the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "X = scaler.transform(x)    \n",
    "\n",
    "#Encoding data\n",
    "le = LabelEncoder()\n",
    "data['label'] = le.fit_transform(data['label'])\n",
    "Y = data['label'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state = 42, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training/ Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores = {'Support Vector Classifier' : [], 'Random Forest Classifier' : [], 'Extreme Gradient Boosting' : [], 'Logistic Regression' : []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.95784543 0.96252927 0.97183099 0.96948357 0.9600939 ]\n",
      "--------------------------------------------------------------------\n",
      "Mean Accuracy: 0.96\n",
      "--------------------------------------------------------------------\n",
      "Standard Deviation: 0.01\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "cv_scores = cross_val_score(clf, X, Y, cv=5)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "mean_accuracy = cv_scores.mean()\n",
    "final_scores['Support Vector Classifier'].append(mean_accuracy)\n",
    "std_deviation = cv_scores.std()\n",
    "print('--------------------------------------------------------------------')\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
    "print('--------------------------------------------------------------------')\n",
    "print(f\"Standard Deviation: {std_deviation:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Accuracy: 0.99\n",
      "--------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       143\n",
      "           1       1.00      1.00      1.00       148\n",
      "           2       0.99      0.97      0.98       136\n",
      "\n",
      "    accuracy                           0.99       427\n",
      "   macro avg       0.99      0.99      0.99       427\n",
      "weighted avg       0.99      0.99      0.99       427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "final_scores['Random Forest Classifier'].append(accuracy)\n",
    "print(f'                      Accuracy: {accuracy:.2f}')\n",
    "print('--------------------------------------------------------------------')\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Accuracy: 0.99\n",
      "--------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       143\n",
      "           1       1.00      1.00      1.00       148\n",
      "           2       0.98      0.99      0.99       136\n",
      "\n",
      "    accuracy                           0.99       427\n",
      "   macro avg       0.99      0.99      0.99       427\n",
      "weighted avg       0.99      0.99      0.99       427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "xgb = XGBClassifier(n_estimators = 15, max_depth = 5, learning_rate = 1)\n",
    "xgb.fit(x_train, y_train)\n",
    "y_pred = xgb.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "final_scores['Extreme Gradient Boosting'].append(accuracy)\n",
    "print(f'                      Accuracy: {accuracy:.2f}')\n",
    "print('--------------------------------------------------------------------')\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Accuracy: 0.98\n",
      "--------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       143\n",
      "           1       1.00      0.99      1.00       148\n",
      "           2       0.97      0.96      0.96       136\n",
      "\n",
      "    accuracy                           0.98       427\n",
      "   macro avg       0.98      0.98      0.98       427\n",
      "weighted avg       0.98      0.98      0.98       427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = LogisticRegression(max_iter = 999)\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "final_scores['Logistic Regression'].append(accuracy)\n",
    "print(f'                      Accuracy: {accuracy:.2f}')\n",
    "print('--------------------------------------------------------------------')\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluating All The Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Support Vector Classifier': [0.9643566315928357], 'Random Forest Classifier': [0.9882903981264637], 'Extreme Gradient Boosting': [0.990632318501171], 'Logistic Regression': [0.9765807962529274]}\n"
     ]
    }
   ],
   "source": [
    "print(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier : [0.9643566315928357]%\n",
      "Random Forest Classifier : [0.9882903981264637]%\n",
      "Extreme Gradient Boosting : [0.990632318501171]%\n",
      "Logistic Regression : [0.9765807962529274]%\n"
     ]
    }
   ],
   "source": [
    "for key, value in final_scores.items():\n",
    "    print(f'{key} : {value}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
